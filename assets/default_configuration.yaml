# =============================================================================
# WORKSPACE-QDRANT-MCP DEFAULT CONFIGURATION - COMPREHENSIVE EDITION
# =============================================================================
#
# This file contains the complete default configuration for the workspace-qdrant-mcp
# system with comprehensive documentation for every configuration option. It serves
# as the single source of truth for all configurable parameters used by both Rust
# and Python implementations.
#
# Data Sources:
# - Production deployment experience across multiple environments
# - Performance optimization research and benchmarking data
# - Qdrant vector database best practices and optimization patterns
# - MCP (Model Context Protocol) specification requirements
# - gRPC communication optimization patterns
# - FastEmbed model performance characteristics
# - File system monitoring and ingestion pipeline optimization
#
# Coverage: All configuration sections with detailed rationale and optimization guidance
# Performance Profiles: Development, staging, and production deployment patterns
# Security Considerations: Authentication, authorization, and data protection options
# Last Updated: 2025-01-20
# =============================================================================

# =============================================================================
# DEPLOYMENT CONFIGURATION
# =============================================================================
# Purpose: Controls deployment-specific behavior including asset file locations,
# base paths, and environment-specific settings. This section determines whether
# the application runs in development mode (using project-relative paths) or
# production mode (using system-installed paths).
deployment:
  # develop: Development mode toggle for asset and configuration file resolution
  # Purpose: Controls whether to use development (project-relative) or production paths
  # Development mode (true): Assets loaded from project "assets/" directory
  # Production mode (false): Assets loaded from system installation directories
  # Security: Production mode provides better isolation and security
  # Maintenance: Production mode enables centralized configuration management
  # Override: Local configurations can set develop=true for development work
  # Default reasoning: false ensures production deployments use proper system paths
  # Platform paths (production mode):
  #   - Linux: /usr/share/workspace-qdrant-mcp/assets/
  #   - macOS: /usr/local/share/workspace-qdrant-mcp/assets/
  #   - Windows: %ProgramFiles%\workspace-qdrant-mcp\assets\
  # Format: Boolean true/false
  develop: false

  # base_path: Override base path for asset and configuration file resolution
  # Purpose: Allows custom base directory when standard paths are not suitable
  # Usage: Optional override for both development and production deployments
  # Examples: "/opt/workspace-qdrant", "/usr/local/workspace-qdrant"
  # Security: Ensure path is readable by application user/service account
  # Precedence: If set, overrides both develop=true and develop=false behavior
  # Format: Absolute directory path string, or null to use defaults
  # Default reasoning: null allows automatic path resolution based on develop flag
  base_path: null

# =============================================================================
# HTTP SERVER CONFIGURATION
# =============================================================================
# Purpose: Configures the HTTP server that handles MCP (Model Context Protocol)
# communication between Claude Desktop and the workspace-qdrant-mcp server.
# This server receives document operations, search requests, and collection
# management commands from MCP clients.
server:
  # host: Network interface binding for HTTP server
  # Purpose: Controls which network interfaces the server listens on for connections
  # Security: "127.0.0.1" restricts to localhost, "0.0.0.0" allows external access
  # Production: Use specific IP or "127.0.0.1" with reverse proxy for security
  # Development: "127.0.0.1" prevents accidental external exposure
  # Format: IP address string
  # Examples: "127.0.0.1", "0.0.0.0", "192.168.1.100"
  host: "127.0.0.1"

  # port: TCP port number for HTTP server binding
  # Purpose: Defines the port where the MCP server accepts HTTP connections
  # Constraints: Must be available and not conflict with system or application ports
  # Common conflicts: 8080 (proxy servers), 8000 (development servers)
  # Production: Use non-standard ports above 1024 for security
  # Load balancing: Configure load balancer to forward to this port
  # Format: Integer 1-65535
  # Default reasoning: 8000 is commonly available and recognizable for HTTP services
  port: 8000

  # debug: Development and diagnostic mode toggle
  # Purpose: Enables enhanced logging, error details, and debugging features
  # Development: Essential for troubleshooting integration and performance issues
  # Production: Disable to reduce log volume and prevent information disclosure
  # Performance impact: Minimal when disabled, 5-10% overhead when enabled
  # Security: May expose internal system details in error responses
  # Format: Boolean
  debug: false

# =============================================================================
# QDRANT VECTOR DATABASE CONFIGURATION
# =============================================================================
# Purpose: Configures connection, authentication, and optimization settings for
# the Qdrant vector database that stores and searches document embeddings.
# Critical for performance, reliability, and scalability of vector operations.
qdrant:
  # url: Qdrant server connection endpoint
  # Purpose: Primary connection URL for Qdrant database operations
  # Local development: "http://localhost:6333" for standard Qdrant installation
  # Docker deployment: "http://qdrant:6333" using service name
  # Qdrant Cloud: "https://xyz-cluster.qdrant.io:6333" with HTTPS
  # gRPC alternative: "grpc://localhost:6334" for binary protocol
  # High availability: Use load balancer URL pointing to Qdrant cluster
  # Format: URL with protocol (http/https/grpc)
  url: "http://localhost:6333"

  # api_key: Authentication credentials for secured Qdrant instances
  # Purpose: Provides authentication for Qdrant Cloud or self-hosted secured instances
  # Qdrant Cloud: Required, obtained from cloud dashboard
  # Self-hosted: Optional, configure via Qdrant server security settings
  # Security: Store in environment variables, not in configuration files
  # Rotation: Support key rotation without service restart
  # Format: String token or null for no authentication
  api_key: null

  # timeout: Request timeout limit for Qdrant operations
  # Purpose: Prevents hanging operations and provides predictable response times
  # Large collections: Increase for operations on millions of vectors
  # Embedding operations: Allow sufficient time for batch vector insertions
  # Search operations: Balance between responsiveness and complex query completion
  # Network considerations: Account for network latency in distributed deployments
  # Format: Duration with unit (ms/s/m)
  # Optimization: Start with default, increase if operations frequently timeout
  timeout: 30s

  # prefer_grpc: Protocol preference for Qdrant communication
  # Purpose: Chooses between gRPC binary protocol and HTTP REST API
  # Performance benefit: gRPC provides 20-30% better throughput and lower latency
  # Binary efficiency: Reduced payload size for large vector operations
  # Streaming support: Better for real-time operations and large data transfers
  # Fallback behavior: Automatically falls back to HTTP if gRPC unavailable
  # Network compatibility: Some corporate networks block gRPC traffic
  # Format: Boolean
  prefer_grpc: true

  # transport: Primary communication protocol selection
  # Purpose: Defines the default protocol for Qdrant server communication
  # "grpc": Binary protocol, optimal for high-performance vector operations
  # "http": REST API, better compatibility but higher overhead
  # Automatic fallback: System tries alternate protocol if primary fails
  # Load balancing: Ensure load balancer supports chosen protocol
  # Format: String enum ("grpc" | "http")
  transport: "grpc"

  # Connection pool configuration for Qdrant client connections
  # Purpose: Manages connection lifecycle, performance, and resource utilization
  # Critical for: High-throughput scenarios, concurrent operations, resource efficiency
  pool:
    # max_connections: Maximum concurrent connections to Qdrant server
    # Purpose: Limits connection count to prevent overwhelming Qdrant server
    # Sizing guideline: 2x expected concurrent operations for optimal performance
    # Resource impact: Each connection consumes memory and file descriptors
    # Qdrant limits: Check server-side connection limits to avoid rejections
    # Monitoring: Track connection utilization to optimize this value
    # Format: Integer > 0
    max_connections: 10

    # min_idle_connections: Minimum connections maintained in idle state
    # Purpose: Reduces connection establishment latency for new operations
    # Performance benefit: Sub-millisecond operation start for cached connections
    # Resource trade-off: Maintains unused connections consuming server resources
    # Sizing: Set to 20-30% of max_connections for balanced performance
    # Cold start mitigation: Prevents connection delays after idle periods
    # Format: Integer >= 0, <= max_connections
    min_idle_connections: 2

    # max_idle_time: Maximum time to retain unused connections
    # Purpose: Balances connection availability with resource conservation
    # Resource management: Closes connections that haven't been used recently
    # Network efficiency: Prevents unnecessary keep-alive traffic
    # Reconnection cost: Consider establishment overhead vs. resource savings
    # Server compatibility: Align with Qdrant server timeout configurations
    # Format: Duration with unit (s/m/h)
    max_idle_time: 5m

    # max_connection_lifetime: Maximum total lifetime for any connection
    # Purpose: Forces connection renewal to prevent staleness and memory leaks
    # Memory management: Prevents long-lived connection memory growth
    # Load balancing: Ensures connections redistribute across server instances
    # Security: Limits exposure time for potentially compromised connections
    # Network reliability: Handles network infrastructure changes gracefully
    # Format: Duration with unit (m/h)
    max_connection_lifetime: 1h

    # acquisition_timeout: Maximum wait time for acquiring pool connection
    # Purpose: Prevents indefinite blocking when connection pool is exhausted
    # Fail-fast behavior: Returns error quickly rather than hanging operations
    # Capacity planning: Indicates when pool sizing needs adjustment
    # User experience: Provides predictable response times under load
    # Monitoring: Track acquisition failures to optimize pool configuration
    # Format: Duration with unit (s/m)
    acquisition_timeout: 30s

  # Circuit breaker configuration for fault tolerance and resilience
  # Purpose: Implements circuit breaker pattern to prevent cascading failures
  # Critical for: Production stability, graceful degradation, fault isolation
  circuit_breaker:
    # enabled: Activates circuit breaker pattern for Qdrant operations
    # Purpose: Enables automatic failure detection and recovery mechanisms
    # Resilience benefit: Prevents cascade failures when Qdrant becomes unavailable
    # Fail-fast behavior: Quickly returns errors instead of waiting for timeouts
    # Recovery automation: Automatically attempts service restoration
    # Monitoring integration: Provides failure metrics for alerting systems
    # Format: Boolean
    enabled: true

    # failure_threshold: Consecutive failures required to open circuit
    # Purpose: Defines sensitivity to failures before cutting off traffic
    # Tuning: Lower values detect issues faster but may be overly sensitive
    # Stability: Higher values provide more tolerance for transient issues
    # Network considerations: Account for expected network flakiness
    # Operational experience: Adjust based on observed failure patterns
    # Format: Integer > 0
    failure_threshold: 5

    # success_threshold: Successful requests needed to close circuit
    # Purpose: Ensures service stability before resuming normal operations
    # Safety mechanism: Prevents flapping between open and closed states
    # Recovery validation: Confirms sustained recovery rather than momentary success
    # Load protection: Gradually restores traffic to recovering service
    # Monitoring: Tracks recovery quality and stability
    # Format: Integer > 0
    success_threshold: 3

    # timeout: Duration circuit remains open before attempting recovery
    # Purpose: Allows time for underlying issues to be resolved
    # Recovery period: Provides buffer for service restoration or failover
    # Exponential backoff: Consider implementing progressive timeout increases
    # Operations alignment: Coordinate with infrastructure recovery procedures
    # User experience: Balance recovery time with service availability
    # Format: Duration with unit (s/m)
    timeout: 60s

    # half_open_timeout: Maximum time for recovery probe requests
    # Purpose: Limits exposure during half-open state testing
    # Risk mitigation: Prevents extended exposure to potentially failing service
    # Recovery testing: Allows sufficient time for meaningful recovery validation
    # Failure detection: Quickly identifies continued service issues
    # State management: Controls transition timing between circuit states
    # Format: Duration with unit (s/m)
    half_open_timeout: 30s

  # Default collection configuration template
  # Purpose: Defines standard settings for new vector collections
  # Applied to: All newly created collections unless explicitly overridden
  # Consistency: Ensures uniform configuration across project collections
  default_collection:
    # vector_size: Dimension count for dense vector embeddings
    # Purpose: Defines vector space dimensionality for embedding storage
    # Critical requirement: Must exactly match embedding model output dimensions
    # Model compatibility: sentence-transformers/all-MiniLM-L6-v2 outputs 384 dimensions
    # Performance impact: Higher dimensions increase memory usage and search time
    # Model examples:
    #   - all-MiniLM-L6-v2: 384 dimensions (balanced performance)
    #   - all-mpnet-base-v2: 768 dimensions (higher quality)
    #   - text-embedding-ada-002: 1536 dimensions (OpenAI)
    # Format: Integer > 0
    vector_size: 384

    # distance_metric: Vector similarity calculation method
    # Purpose: Defines how vector similarity is computed for search operations
    # "Cosine": Normalized dot product, ideal for text embeddings (magnitude-independent)
    # "Euclidean": L2 distance, suitable for image/audio embeddings (magnitude-sensitive)
    # "Dot": Raw dot product, fastest but requires normalized vectors
    # Embedding compatibility: Most text embedding models optimized for cosine similarity
    # Performance characteristics: Cosine < Dot < Euclidean (speed), Euclidean < Cosine < Dot (accuracy for text)
    # Format: String enum ("Cosine" | "Euclidean" | "Dot")
    distance_metric: "Cosine"

    # enable_indexing: Vector index construction for search acceleration
    # Purpose: Controls whether HNSW index is built for fast approximate search
    # Performance impact: 10-100x faster search with index vs. brute force
    # Memory overhead: Indexes consume additional RAM (typically 20-50% of vector data)
    # Build time: Index construction adds initial overhead during collection creation
    # Search quality: Approximate results with configurable precision/recall trade-offs
    # Small collections: May use brute force regardless (see full_scan_threshold)
    # Format: Boolean
    enable_indexing: true

    # replication_factor: Data redundancy and availability configuration
    # Purpose: Controls how many copies of each vector are stored across cluster nodes
    # High availability: Values > 1 provide fault tolerance for node failures
    # Single node deployment: Value of 1 is optimal (no redundancy possible)
    # Cluster deployment: Recommended minimum of 2 for production resilience
    # Storage cost: Each replica multiplies storage requirements
    # Write performance: Higher replication increases write latency
    # Format: Integer >= 1
    replication_factor: 1

    # shard_number: Horizontal scaling and data distribution configuration
    # Purpose: Controls how collection data is distributed across multiple shards
    # Single shard: Optimal for collections under 1M vectors
    # Multiple shards: Required for horizontal scaling beyond single node capacity
    # Performance scaling: More shards enable parallel processing of operations
    # Memory distribution: Spreads memory load across multiple nodes
    # Query coordination: Search requests fan out across all shards
    # Optimal sizing: Consider shard count = node count for balanced distribution
    # Format: Integer >= 1
    shard_number: 1

    # on_disk_vectors: Vector storage location configuration
    # Purpose: Controls whether vectors are stored in memory or on disk
    # Memory storage (false): Fastest access, highest performance, limited capacity
    # Disk storage (true): Larger capacity, slower access, reduced memory usage
    # Performance impact: Memory storage provides 10-100x faster access
    # Capacity trade-off: Disk storage enables collections beyond RAM capacity
    # Hybrid approach: Qdrant automatically manages memory/disk based on usage patterns
    # Production sizing: Choose based on working set size vs. available RAM
    # Format: Boolean
    on_disk_vectors: false

    # HNSW (Hierarchical Navigable Small World) index configuration
    # Purpose: Fine-tunes the vector index for optimal search performance
    # Critical for: Search speed, accuracy, memory usage, and index build time
    hnsw:
      # m: Bidirectional link count per node during index construction
      # Purpose: Controls graph connectivity and search accuracy
      # Higher values: Better recall, more memory usage, slower construction
      # Lower values: Faster construction, less memory, potentially lower recall
      # Typical range: 4-64, with 16 providing good balance
      # Memory impact: Each link consumes additional index memory
      # Search performance: More links provide better navigation paths
      # Format: Integer 4-64
      m: 16

      # ef_construct: Candidate list size during index construction
      # Purpose: Controls index quality vs. construction time trade-off
      # Higher values: Better index quality, longer construction time
      # Lower values: Faster construction, potentially worse search performance
      # Typical range: 16-512, with 100 providing good balance
      # One-time cost: Only affects initial index build, not runtime search
      # Quality impact: Directly influences long-term search recall
      # Format: Integer 16-512
      ef_construct: 100

      # ef: Dynamic candidate list size during search operations
      # Purpose: Controls search accuracy vs. speed trade-off at query time
      # Higher values: Better recall, slower search
      # Lower values: Faster search, potentially lower recall
      # Runtime tunable: Can be adjusted per-query for different accuracy needs
      # Typical range: 16-512, with 64 providing good balance
      # Performance scaling: Linear impact on search time
      # Format: Integer 16-512
      ef: 64

      # full_scan_threshold: Collection size limit for exact search
      # Purpose: Determines when to use brute force vs. approximate search
      # Below threshold: Uses exact search for perfect recall
      # Above threshold: Uses HNSW index for fast approximate search
      # Exact search benefits: Perfect recall, no index memory overhead
      # Approximate search benefits: Scalable performance for large collections
      # Threshold tuning: Balance between perfect accuracy and search speed
      # Format: Integer > 0
      full_scan_threshold: 10000

# =============================================================================
# EMBEDDING SERVICE CONFIGURATION
# =============================================================================
# Purpose: Configures the text embedding pipeline that converts documents into
# vector representations for semantic search. Critical for search quality,
# performance, and system resource utilization.
embedding:
  # model: FastEmbed model identifier for text vectorization
  # Purpose: Specifies which pre-trained model to use for generating text embeddings
  # Performance characteristics: Balanced speed/quality model selection
  # Quality considerations: all-MiniLM-L6-v2 provides good semantic understanding
  # Multilingual options: Consider e5-small-v2 for non-English content
  # Specialization: Choose domain-specific models for technical/scientific content
  # Model examples:
  #   - sentence-transformers/all-MiniLM-L6-v2: 384d, fast, good quality
  #   - sentence-transformers/all-mpnet-base-v2: 768d, slower, higher quality
  #   - BAAI/bge-small-en-v1.5: 384d, optimized for English
  #   - intfloat/e5-small-v2: 384d, multilingual support
  # Compatibility: vector_size must match model output dimensions
  # Format: String model identifier
  model: "sentence-transformers/all-MiniLM-L6-v2"

  # enable_sparse_vectors: Hybrid search capability activation
  # Purpose: Enables generation of sparse keyword vectors alongside dense semantic vectors
  # Search improvement: Combines semantic similarity with exact keyword matching
  # Recall enhancement: Improves performance on specific terms and proper nouns
  # Storage overhead: Approximately 10-20% additional storage for sparse vectors
  # Processing cost: Minimal additional CPU overhead during embedding
  # Search fusion: Uses Reciprocal Rank Fusion (RRF) to combine results
  # Format: Boolean
  enable_sparse_vectors: true

  # chunk_size: Maximum character count per text segment
  # Purpose: Controls text segmentation for embedding processing
  # Context preservation: Larger chunks maintain more semantic context
  # Detail capture: Smaller chunks provide more granular search results
  # Model limits: Most embedding models have maximum input length constraints
  # Search relevance: Chunk size affects relevance of search results
  # Memory usage: Larger chunks consume more processing memory
  # Optimization: Balance between context and precision based on content type
  # Format: Integer characters
  chunk_size: 800

  # chunk_overlap: Character overlap between consecutive text segments
  # Purpose: Preserves context across chunk boundaries to prevent information loss
  # Context continuity: Ensures sentences/paragraphs aren't split awkwardly
  # Search coverage: Improves recall for queries spanning chunk boundaries
  # Processing overhead: Slight increase in total vectors due to overlapping content
  # Deduplication: Search results may contain overlapping content snippets
  # Sizing guideline: 10-20% of chunk_size for optimal context preservation
  # Format: Integer characters
  chunk_overlap: 120

  # batch_size: Concurrent text chunks processed for embedding
  # Purpose: Controls parallelization and memory usage during embedding operations
  # Throughput optimization: Higher values increase processing speed
  # Memory constraints: Larger batches consume more RAM during processing
  # Model efficiency: Most embedding models optimize for batch processing
  # Resource utilization: Balance between speed and memory consumption
  # Error isolation: Smaller batches isolate failures to fewer documents
  # Performance tuning: Adjust based on available memory and processing cores
  # Format: Integer > 0
  batch_size: 50

# =============================================================================
# WORKSPACE MANAGEMENT CONFIGURATION
# =============================================================================
# Purpose: Controls project detection, collection organization, and file processing
# behavior. Defines how the system discovers projects, organizes content, and
# manages different types of documents across workspaces.
workspace:
  # collection_types: Project-specific collection suffix definitions
  # Purpose: Defines specialized collections within each detected project
  # Organization pattern: Creates {project_name}-{suffix} collections
  # Content separation: Allows different content types to be organized separately
  # Example usage: ["code", "docs", "tests"] creates myproject-code, myproject-docs
  # Search optimization: Enables targeted search within specific content types
  # Empty default: Prevents automatic creation of potentially unwanted collections
  # Management overhead: Each collection type multiplies storage and index overhead
  # Format: Array of strings
  collection_types: []

  # global_collections: Cross-project shared collection definitions
  # Purpose: Defines collections that span multiple projects or contain shared resources
  # Use cases: Common libraries, shared documentation, organization-wide templates
  # Naming pattern: Collections created with exact names specified (no project prefix)
  # Content sharing: Enables knowledge sharing across project boundaries
  # Access patterns: All projects can read/write to these collections
  # Example usage: ["shared-docs", "templates", "common-libs"]
  # Format: Array of strings
  global_collections: []

  # github_user: Project filtering by GitHub ownership
  # Purpose: Restricts project detection to repositories owned by specific user/organization
  # Security: Prevents processing of unintended repositories
  # Multi-user systems: Isolates user-specific projects in shared environments
  # Repository detection: Checks .git/config remote.origin.url for username match
  # Organization support: Works with both individual users and GitHub organizations
  # Privacy: Ensures only authorized repositories are indexed
  # Format: String username or null for no filtering
  github_user: null

  # auto_create_collections: Automatic collection provisioning
  # Purpose: Controls whether collections are created automatically on first document
  # Zero-configuration: Enables automatic setup without manual collection creation
  # Resource control: Prevents accidental creation of unwanted collections
  # Development convenience: Automatic creation simplifies development workflow
  # Production caution: May create collections with suboptimal configurations
  # Monitoring: Automatic creation should be monitored for unexpected collections
  # Format: Boolean
  auto_create_collections: false

  # memory_collection_name: Cross-session persistent storage identifier
  # Purpose: Defines collection name for storing persistent context and learning data
  # Session continuity: Maintains context across multiple work sessions
  # Learning persistence: Stores user preferences, project insights, and interaction patterns
  # System reserved: This collection is managed by the system, not user content
  # Naming convention: Underscore prefix indicates system collection
  # Backup importance: Contains valuable learned context that should be preserved
  # Format: String collection name
  memory_collection_name: "__memory"

  # code_collection_name: Source code analysis storage identifier
  # Purpose: Defines collection name for specialized source code analysis and symbol lookup
  # Code understanding: Stores extracted symbols, functions, classes, and relationships
  # Symbol search: Enables fast lookup of code definitions and references
  # Language agnostic: Works with all supported programming languages
  # LSP integration: Complements LSP servers with vector-based code search
  # Development workflow: Supports code navigation and understanding tasks
  # Format: String collection name
  code_collection_name: "__code"

  # custom_include_patterns: Additional file pattern recognition
  # Purpose: Extends built-in file type detection with custom patterns
  # Pattern format: Supports glob patterns for flexible file matching
  # Use cases: Proprietary file formats, custom documentation types, specialized content
  # Language detection: Custom patterns integrate with existing language detection
  # Processing pipeline: Matched files undergo standard embedding and indexing
  # Example patterns: ["*.custom", "special/**/*.txt", "config/*.yaml"]
  # Format: Array of glob pattern strings
  custom_include_patterns: []

  # custom_exclude_patterns: Additional file exclusion rules
  # Purpose: Extends built-in exclusion patterns with project-specific rules
  # Security: Exclude sensitive files that shouldn't be indexed
  # Performance: Skip large files that don't contribute to search quality
  # Privacy: Exclude personal or confidential content from indexing
  # Pattern inheritance: Combines with built-in exclusions from languages_support.yaml
  # Example patterns: ["secret/**", "*.backup", "temp/*.log", "*.key"]
  # Format: Array of glob pattern strings
  custom_exclude_patterns: []

  # custom_project_indicators: Specialized project detection rules
  # Purpose: Defines custom file patterns that indicate project boundaries
  # Project types: Supports detection of specialized development environments
  # Framework support: Enables detection of custom frameworks or toolchains
  # Organization standards: Accommodate company-specific project structures
  # Detection priority: Custom indicators are checked alongside standard patterns
  # Example: { "unity": ["Assets/", "ProjectSettings/"], "custom": ["project.yaml"] }
  # Format: Object with project type keys and file pattern arrays
  custom_project_indicators: {}

# =============================================================================
# gRPC COMMUNICATION CONFIGURATION
# =============================================================================
# Purpose: Configures high-performance gRPC communication layer between Rust
# engine and Python MCP server. Critical for system performance, reliability,
# and inter-process communication efficiency.
grpc:
  # enabled: gRPC server activation control
  # Purpose: Enables or disables the gRPC communication layer
  # Performance benefit: gRPC provides 2-3x better performance than HTTP for binary data
  # Compatibility: Some network environments may block gRPC traffic
  # Fallback behavior: System automatically falls back to direct Qdrant access if disabled
  # Development: Can be disabled for simplified debugging and testing
  # Production: Recommended to enable for optimal performance
  # Format: Boolean
  enabled: true

  # host: gRPC server network binding configuration
  # Purpose: Controls network interface for gRPC server listening
  # Local communication: "127.0.0.1" restricts to local inter-process communication
  # Distributed deployment: "0.0.0.0" allows remote gRPC clients (requires security)
  # Security consideration: Local binding prevents external gRPC access
  # Container deployment: May need "0.0.0.0" for container-to-container communication
  # Network isolation: Use specific IP for controlled network access
  # Format: IP address string
  host: "127.0.0.1"

  # port: gRPC server TCP port assignment
  # Purpose: Defines port for gRPC service communication
  # Port separation: Different from HTTP server port to avoid conflicts
  # Standard gRPC: Port 50051 is commonly used for gRPC services
  # Firewall configuration: Ensure port is accessible between components
  # Load balancing: Configure load balancer for gRPC protocol support
  # Container mapping: Map container port to host port in containerized deployments
  # Format: Integer 1024-65535
  port: 50051

  # fallback_to_direct: Direct Qdrant access when gRPC unavailable
  # Purpose: Enables automatic fallback to direct Qdrant communication
  # Resilience: Ensures system functionality even if gRPC server fails
  # Performance degradation: Direct access is slower but maintains functionality
  # Error recovery: Automatic failover provides better user experience
  # Monitoring: Track fallback usage to identify gRPC reliability issues
  # Development: Useful for testing scenarios with disabled gRPC
  # Format: Boolean
  fallback_to_direct: true

  # connection_timeout: gRPC connection establishment limit
  # Purpose: Maximum time allowed for establishing gRPC connections
  # Network reliability: Accounts for network latency and congestion
  # Fail-fast behavior: Prevents hanging on unavailable gRPC servers
  # Container startup: Allow sufficient time for containerized service startup
  # Development: Shorter timeouts speed up development feedback cycles
  # Production: Balance between responsiveness and reliability
  # Format: Duration with unit (ms/s)
  connection_timeout: 10s

  # max_retries: gRPC operation retry limit configuration
  # Purpose: Controls retry attempts for failed gRPC operations
  # Reliability improvement: Handles transient network and service issues
  # Performance consideration: More retries increase operation latency on failures
  # Exponential backoff: Retry delays increase progressively to avoid overwhelming services
  # Circuit breaker integration: Works with circuit breaker for comprehensive fault tolerance
  # Monitoring: Track retry patterns to identify systemic issues
  # Format: Integer >= 0
  max_retries: 3

  # retry_backoff_multiplier: Exponential backoff progression control
  # Purpose: Controls delay increase between successive retry attempts
  # Backoff calculation: delay = base_delay * multiplier^retry_attempt
  # Service protection: Prevents overwhelming recovering services with immediate retries
  # Network congestion: Reduces load during network congestion periods
  # Typical values: 1.5-2.0 for balanced recovery without excessive delays
  # Jitter consideration: Implementation may add random jitter to prevent thundering herd
  # Format: Float >= 1.0
  retry_backoff_multiplier: 1.5

  # health_check_interval: gRPC service health monitoring frequency
  # Purpose: Defines interval for proactive gRPC server health checks
  # Early detection: Identifies service issues before user operations fail
  # Resource overhead: More frequent checks consume network and CPU resources
  # Recovery timing: Affects how quickly service recovery is detected
  # Alerting integration: Health check failures can trigger monitoring alerts
  # Load balancing: Health status can influence traffic routing decisions
  # Format: Duration with unit (s/m)
  health_check_interval: 30s

  # max_message_length: gRPC message size limit configuration
  # Purpose: Maximum size allowed for individual gRPC messages
  # Large document support: Must accommodate largest expected document or batch operation
  # Memory protection: Prevents excessive memory allocation for malformed requests
  # Performance optimization: Larger limits enable efficient batch operations
  # Network efficiency: Single large message vs. multiple small messages trade-off
  # Default reasoning: 100MB supports most document types while preventing abuse
  # Format: Size with unit (B/KB/MB/GB)
  max_message_length: 100MB

  # keepalive_time: Connection maintenance interval
  # Purpose: Frequency of keepalive messages to maintain idle connections
  # Connection preservation: Prevents idle connections from being closed by network infrastructure
  # NAT/Firewall traversal: Keeps connection state active in network devices
  # Resource usage: Balance between connection reliability and network overhead
  # Mobile networks: Shorter intervals may be needed for mobile/wireless connections
  # Server compatibility: Align with server-side keepalive configurations
  # Format: Duration with unit (s/m)
  keepalive_time: 30s

# =============================================================================
# AUTO-INGESTION CONFIGURATION
# =============================================================================
# Purpose: Controls automatic document processing, file system monitoring, and
# real-time ingestion pipeline. Critical for maintaining up-to-date vector
# search indexes as project files change.
auto_ingestion:
  # enabled: Master control for automatic document processing
  # Purpose: Enables or disables the entire auto-ingestion system
  # Development convenience: Automatically processes new and modified files
  # Resource control: Can be disabled to reduce system load during intensive operations
  # Manual control: When disabled, documents must be manually added to collections
  # Performance impact: Background processing may affect system responsiveness
  # Battery consideration: Continuous monitoring may impact battery life on laptops
  # Format: Boolean
  enabled: true

  # auto_create_watches: File system monitoring activation
  # Purpose: Enables automatic file system watch setup for project directories
  # Real-time updates: Monitors file changes and triggers automatic processing
  # Resource efficiency: Uses OS-level file system events instead of polling
  # Scalability: Handles large project directories efficiently
  # Platform support: Works across Windows, macOS, and Linux file systems
  # Watch limits: May hit OS limits on maximum watched directories for very large projects
  # Format: Boolean
  auto_create_watches: true

  # include_common_files: Standard project file processing
  # Purpose: Automatically processes common project documentation and configuration files
  # Documentation coverage: Includes README, LICENSE, CHANGELOG, and similar files
  # Configuration awareness: Processes package.json, pyproject.toml, and build configurations
  # Project understanding: Enables search across project metadata and documentation
  # File type examples: README.md, LICENSE, package.json, Cargo.toml, requirements.txt
  # Search utility: Makes project information discoverable through vector search
  # Format: Boolean
  include_common_files: true

  # include_source_files: Source code file processing control
  # Purpose: Controls whether source code files are automatically processed for content indexing
  # Code search: Enables semantic search across source code content
  # Volume consideration: Source files can generate large numbers of vectors
  # Performance impact: Processing all source files may significantly increase index size
  # Complementary: Works alongside LSP servers for comprehensive code understanding
  # Selective processing: Consider enabling only for specific file types or directories
  # Format: Boolean
  include_source_files: false

  # target_collection_suffix: Default collection destination for auto-ingested content
  # Purpose: Defines which collection receives automatically processed files
  # Organization: Groups auto-ingested content into designated collections
  # Collection naming: Results in {project_name}-{suffix} collection names
  # Content separation: Distinguishes auto-ingested from manually curated content
  # Search scoping: Enables targeted search within auto-ingested content
  # Default rationale: "scratchbook" suggests working notes and discovered content
  # Format: String collection suffix
  target_collection_suffix: "scratchbook"

  # max_files_per_batch: Batch processing size limit
  # Purpose: Controls maximum number of files processed simultaneously
  # Memory management: Prevents excessive memory usage during large batch operations
  # Processing efficiency: Balances throughput with resource consumption
  # Error isolation: Smaller batches limit impact of processing failures
  # Progress tracking: Enables incremental progress reporting for large operations
  # Tuning: Adjust based on available memory and average file sizes
  # Format: Integer > 0
  max_files_per_batch: 5

  # batch_delay: Processing interval between batch operations
  # Purpose: Introduces delay between consecutive batch processing cycles
  # System responsiveness: Prevents auto-ingestion from overwhelming system resources
  # User experience: Ensures interactive operations remain responsive
  # CPU throttling: Allows other processes to use CPU during processing pauses
  # File stability: Provides time for files to finish being written before processing
  # Power management: Reduces continuous CPU usage for better battery life
  # Format: Duration with unit (s/m)
  batch_delay: 2s

  # max_file_size: Individual file size limit for processing
  # Purpose: Prevents processing of extremely large files that may cause resource issues
  # Memory protection: Avoids loading huge files that could exhaust available memory
  # Processing timeout: Large files may exceed processing time limits
  # Quality consideration: Very large files may not benefit from vector search
  # Binary exclusion: Helps exclude large binary files that aren't text-searchable
  # Override capability: Critical files can be manually processed regardless of size
  # Format: Size with unit (B/KB/MB/GB)
  max_file_size: 50MB

  # debounce: File change stabilization delay
  # Purpose: Waits for file changes to stabilize before triggering processing
  # Write completion: Ensures files are completely written before processing
  # Edit session handling: Avoids processing partial edits during active editing
  # Resource efficiency: Reduces redundant processing of rapidly changing files
  # User experience: Prevents constant reprocessing during development activities
  # Network files: May need longer delays for network-mounted file systems
  # Format: Duration with unit (ms/s)
  debounce: 10s

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# Purpose: Controls system logging, metrics collection, and diagnostic output.
# Critical for monitoring, debugging, and operational visibility.
logging:
  # level: Minimum log message severity for output
  # Purpose: Controls verbosity of log output and filters messages by importance
  # Severity levels: "trace" < "debug" < "info" < "warn" < "error" (increasing severity)
  # Development: Use "debug" or "trace" for detailed diagnostic information
  # Production: Use "info" or "warn" to reduce log volume and focus on important events
  # Performance impact: Lower levels generate more log messages, affecting performance
  # Storage consideration: Verbose logging consumes significant disk space over time
  # Format: String enum ("trace" | "debug" | "info" | "warn" | "error")
  level: "info"

  # use_file_logging: File-based vs. console logging selection
  # Purpose: Controls whether logs are written to files or standard output streams
  # Console logging: Suitable for development and containerized environments
  # File logging: Better for production deployments requiring log persistence
  # Log rotation: File logging typically supports automatic log rotation
  # Container compatibility: Console logging integrates better with container orchestration
  # Debugging: File logging preserves logs for post-mortem analysis
  # Format: Boolean
  use_file_logging: false

  # log_file: Log file location specification
  # Purpose: Defines file path when file logging is enabled
  # Automatic generation: null value triggers automatic path generation
  # Path requirements: Directory must exist and be writable by application
  # Rotation considerations: Consider log rotation policies for long-running services
  # Monitoring integration: Log aggregation tools may require specific paths
  # Example paths: "/var/log/workspace-qdrant-mcp.log", "logs/app.log"
  # Format: String file path or null
  log_file: null

  # enable_metrics: Performance metrics collection activation
  # Purpose: Enables collection and exposure of performance and usage metrics
  # Monitoring integration: Provides data for monitoring dashboards and alerting
  # Performance overhead: Metrics collection adds 1-3% CPU overhead
  # Operational visibility: Essential for production monitoring and optimization
  # Debugging aid: Metrics help identify performance bottlenecks and usage patterns
  # Privacy consideration: Metrics may contain usage patterns and performance data
  # Format: Boolean
  enable_metrics: false

  # metrics_interval: Metrics collection and reporting frequency
  # Purpose: Controls how often metrics are collected and potentially reported
  # Resource usage: More frequent collection increases CPU and memory overhead
  # Monitoring granularity: Higher frequency provides better temporal resolution
  # Storage impact: Frequent metrics generate more monitoring data
  # Alerting sensitivity: Collection frequency affects alerting responsiveness
  # Network overhead: If metrics are exported, frequency affects network usage
  # Format: Duration with unit (s/m)
  metrics_interval: 60s

# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================
# Purpose: Controls resource utilization, concurrency, and performance optimization
# settings. Critical for balancing system responsiveness, throughput, and resource consumption.
performance:
  # max_concurrent_tasks: Parallel operation limit
  # Purpose: Controls maximum number of operations that can execute simultaneously
  # CPU utilization: Align with CPU core count for CPU-bound operations
  # I/O operations: Can exceed core count for I/O-bound operations like file processing
  # Memory pressure: More concurrent tasks increase memory usage
  # System responsiveness: Too many concurrent tasks can reduce system responsiveness
  # Optimal sizing: Start with CPU core count and adjust based on workload characteristics
  # Format: Integer > 0
  max_concurrent_tasks: 4

  # default_timeout: Standard operation timeout limit
  # Purpose: Default timeout applied to operations that don't specify their own timeout
  # Operation coverage: Applies to embedding, vectorization, and search operations
  # Reliability: Prevents operations from hanging indefinitely
  # User experience: Provides predictable response times
  # Resource protection: Prevents resource leaks from stuck operations
  # Network consideration: Account for network latency in distributed deployments
  # Format: Duration with unit (ms/s/m)
  default_timeout: 30s

  # enable_preemption: Task interruption capability
  # Purpose: Allows higher priority operations to interrupt lower priority tasks
  # Responsiveness: Interactive operations can preempt background processing
  # User experience: Ensures UI operations remain responsive during batch processing
  # Resource fairness: Prevents background tasks from monopolizing system resources
  # Implementation complexity: Adds complexity to task scheduling and resource management
  # Safety consideration: Preempted tasks must handle interruption gracefully
  # Format: Boolean
  enable_preemption: true

  # chunk_size: Default batch processing unit size
  # Purpose: Standard chunk size for batch operations on large collections
  # Memory efficiency: Controls memory usage during bulk operations
  # Progress reporting: Enables incremental progress updates for long operations
  # Error resilience: Smaller chunks limit impact of processing failures
  # Performance tuning: Balance between processing efficiency and resource usage
  # Operation types: Applies to bulk insertions, searches, and collection operations
  # Format: Integer > 0
  chunk_size: 1000

# =============================================================================
# RUST-SPECIFIC CONFIGURATION
# =============================================================================
# Purpose: Additional configuration options specific to the Rust engine component
# that are not shared with Python implementations. Controls Rust-specific
# optimizations, client behavior, and system integration patterns.
rust:
  # Rust client configuration for Qdrant communication optimization
  # Purpose: Fine-tunes Rust-specific client behavior and performance characteristics
  # Performance focus: Optimized for Rust's memory management and concurrency model
  # Integration: Complements general Qdrant configuration with Rust-specific optimizations
  client:
    # connection_timeout: Rust client connection establishment timeout
    # Purpose: Maximum time Rust client waits for Qdrant connection establishment
    # Network resilience: Handles network latency and connection issues
    # Fail-fast behavior: Prevents Rust processes from hanging on connection failures
    # Container deployment: Account for service discovery and startup delays
    # Development: Shorter timeouts provide faster feedback during development
    # Format: Duration with unit (s/m)
    connection_timeout: 30s

    # request_timeout: Individual Rust client request timeout
    # Purpose: Maximum time allowed for individual Qdrant requests from Rust client
    # Operation coverage: Applies to vector insertions, searches, and collection operations
    # Large operations: Vector batch insertions may require longer timeouts
    # Memory management: Rust's zero-copy optimizations may handle large requests efficiently
    # Error handling: Rust client can handle timeouts gracefully with proper error propagation
    # Format: Duration with unit (s/m)
    request_timeout: 60s

    # max_retries: Rust client retry attempt limit
    # Purpose: Maximum retry attempts for failed Rust client operations
    # Reliability: Rust's error handling enables sophisticated retry logic
    # Performance: Rust's low overhead makes retries less expensive
    # Circuit breaker integration: Works with Rust-based circuit breaker implementations
    # Logging: Rust client can provide detailed retry attempt logging
    # Format: Integer >= 0
    max_retries: 3

    # retry_delay: Base delay between Rust client retry attempts
    # Purpose: Initial delay before first retry attempt in exponential backoff
    # Exponential progression: Subsequent delays increase based on backoff multiplier
    # Service protection: Prevents overwhelming services with immediate retries
    # Rust efficiency: Low-overhead timers enable precise delay control
    # Jitter support: Rust implementation can add random jitter to prevent synchronized retries
    # Format: Duration with unit (ms/s)
    retry_delay: 1s

    # max_retry_delay: Maximum delay cap for Rust client retry attempts
    # Purpose: Upper limit for exponential backoff to prevent excessive wait times
    # User experience: Ensures retries don't become indefinitely long
    # Resource efficiency: Prevents threads from being blocked for excessive periods
    # Operational control: Provides predictable maximum delay for operational planning
    # Rust async: Integrates with Rust's async runtime for efficient delay handling
    # Format: Duration with unit (s/m)
    max_retry_delay: 30s